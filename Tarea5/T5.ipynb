{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tarea5ic.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "i50TvQIr90uz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i50TvQIr90uz"
      },
      "source": [
        "# **Tarea 5: Algoritmos de Clustering**\n",
        "**Nombre:** José Luis Cádiz\n",
        "\n",
        "**ReadMe:** Ejecutar todo el código, si se ejecuta solo una parte aislada pueden existir errores producto de que hay variables que se sobreescriben. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kmoJlzA-Zh0"
      },
      "source": [
        "# **Introducción:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft56PQPo0XZP"
      },
      "source": [
        "**En el contexto del curso ''Inteligencia Computacional'', se presentará a continuación el desarrollo de la ''Tarea 5'' del curso. Esta tarea pretende clusterizar un conjunto de datos  que contiene 22 caracteristicas de 10 ranas distintas utilizando tres algoritmos de clustering: k-means, DBSCAN y clustering aglomerativo, esto con el objetivo de analizar el desempeño de cada clusterización según diversas metricas.**\n",
        "\n",
        "**En esta experiencia se usarán las librerías pandas, numpy y scikit-learn para manipular, procesar y clusterizar los datos.**\n",
        "\n",
        "**A continuación se explica a grandes razgos lo que se realizará en la tarea: En la parte 1, se implementará un código que permita leer la base de datos, separando las caractericas y labels, transformando estos ultimos en números de 0 a 9.**\n",
        "\n",
        "**En la parte 2, se modificará la función bench_k_means( ) agregando una columna extra, correspondiente al número de\n",
        "clusters.** \n",
        "\n",
        "**En la parte 3, se implementará una nueva función bench_clustering2( ), tomando como base la función\n",
        "bench_k_means( ) modificada en el punto anterior. Esta función será usada para obtener un\n",
        "benchmark para k-means, DBSCAN y clustering aglomerativo.**\n",
        "\n",
        "**En la parte 4, se harán pruebas con distintas variantes de los algoritmos mencionados.**\n",
        "\n",
        "**En la parte 5, se analizarán los resultados obtenidos comparando el desempeño de cada algoritmo según las metricas obtenidas, con las variantes de considerar los outliers como un cluster extra  y el efecto del PCA.**\n",
        "\n",
        "\n",
        "**Finalmente, se termina el documento con las conclusiones principales de esta experiencia.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6plIGz2H4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d27275-8762-4559-fb2e-2774e569d06b"
      },
      "source": [
        "#Importando librerias:\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#Libreria sklearn:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#Para el calculo de tiempos de entrenamiento:\n",
        "from time import time\n",
        "\n",
        "#Importar datos desde google drive:\n",
        "from google.colab import drive  #Se uso para no subir el archivo cada vez que se avanzaba en la tarea\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU-irOkbpegK"
      },
      "source": [
        "**Parte 1:** Implemente un código que lea la base de datos. Se recomienda usar la biblioteca Pandas. Los datos\n",
        "se deben dividir en características (MFCCs_1 – MFCCs_22) y labels (Species). Los labels deben\n",
        "transformarse a números en el rango 0-9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPXyernkCE0N",
        "outputId": "8736d6e2-3317-461d-f12c-830b8b3b1268"
      },
      "source": [
        "# Lectura de la Base de Datos:\n",
        "path = 'drive/My Drive/Inteligencia Computacional/Frogs_MFCCs.csv' # Cambiar path*\n",
        "datos=pd.read_csv(path)\n",
        "print(datos.head())\n",
        "print(datos.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  ...      Genus         Species  RecordID\n",
            "0       1.0  0.152936 -0.105586  ...  Adenomera  AdenomeraAndre         1\n",
            "1       1.0  0.171534 -0.098975  ...  Adenomera  AdenomeraAndre         1\n",
            "2       1.0  0.152317 -0.082973  ...  Adenomera  AdenomeraAndre         1\n",
            "3       1.0  0.224392  0.118985  ...  Adenomera  AdenomeraAndre         1\n",
            "4       1.0  0.087817 -0.068345  ...  Adenomera  AdenomeraAndre         1\n",
            "\n",
            "[5 rows x 26 columns]\n",
            "(7195, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "h5PfeDY4FyxO",
        "outputId": "3c93e9de-f385-4982-8942-25d66dc7b3db"
      },
      "source": [
        "# Características:\n",
        "features=datos.iloc[:,0:22]\n",
        "data=features\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MFCCs_ 1</th>\n",
              "      <th>MFCCs_ 2</th>\n",
              "      <th>MFCCs_ 3</th>\n",
              "      <th>MFCCs_ 4</th>\n",
              "      <th>MFCCs_ 5</th>\n",
              "      <th>MFCCs_ 6</th>\n",
              "      <th>MFCCs_ 7</th>\n",
              "      <th>MFCCs_ 8</th>\n",
              "      <th>MFCCs_ 9</th>\n",
              "      <th>MFCCs_10</th>\n",
              "      <th>MFCCs_11</th>\n",
              "      <th>MFCCs_12</th>\n",
              "      <th>MFCCs_13</th>\n",
              "      <th>MFCCs_14</th>\n",
              "      <th>MFCCs_15</th>\n",
              "      <th>MFCCs_16</th>\n",
              "      <th>MFCCs_17</th>\n",
              "      <th>MFCCs_18</th>\n",
              "      <th>MFCCs_19</th>\n",
              "      <th>MFCCs_20</th>\n",
              "      <th>MFCCs_21</th>\n",
              "      <th>MFCCs_22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.152936</td>\n",
              "      <td>-0.105586</td>\n",
              "      <td>0.200722</td>\n",
              "      <td>0.317201</td>\n",
              "      <td>0.260764</td>\n",
              "      <td>0.100945</td>\n",
              "      <td>-0.150063</td>\n",
              "      <td>-0.171128</td>\n",
              "      <td>0.124676</td>\n",
              "      <td>0.188654</td>\n",
              "      <td>-0.075622</td>\n",
              "      <td>-0.156436</td>\n",
              "      <td>0.082245</td>\n",
              "      <td>0.135752</td>\n",
              "      <td>-0.024017</td>\n",
              "      <td>-0.108351</td>\n",
              "      <td>-0.077623</td>\n",
              "      <td>-0.009568</td>\n",
              "      <td>0.057684</td>\n",
              "      <td>0.118680</td>\n",
              "      <td>0.014038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.171534</td>\n",
              "      <td>-0.098975</td>\n",
              "      <td>0.268425</td>\n",
              "      <td>0.338672</td>\n",
              "      <td>0.268353</td>\n",
              "      <td>0.060835</td>\n",
              "      <td>-0.222475</td>\n",
              "      <td>-0.207693</td>\n",
              "      <td>0.170883</td>\n",
              "      <td>0.270958</td>\n",
              "      <td>-0.095004</td>\n",
              "      <td>-0.254341</td>\n",
              "      <td>0.022786</td>\n",
              "      <td>0.163320</td>\n",
              "      <td>0.012022</td>\n",
              "      <td>-0.090974</td>\n",
              "      <td>-0.056510</td>\n",
              "      <td>-0.035303</td>\n",
              "      <td>0.020140</td>\n",
              "      <td>0.082263</td>\n",
              "      <td>0.029056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.152317</td>\n",
              "      <td>-0.082973</td>\n",
              "      <td>0.287128</td>\n",
              "      <td>0.276014</td>\n",
              "      <td>0.189867</td>\n",
              "      <td>0.008714</td>\n",
              "      <td>-0.242234</td>\n",
              "      <td>-0.219153</td>\n",
              "      <td>0.232538</td>\n",
              "      <td>0.266064</td>\n",
              "      <td>-0.072827</td>\n",
              "      <td>-0.237384</td>\n",
              "      <td>0.050791</td>\n",
              "      <td>0.207338</td>\n",
              "      <td>0.083536</td>\n",
              "      <td>-0.050691</td>\n",
              "      <td>-0.023590</td>\n",
              "      <td>-0.066722</td>\n",
              "      <td>-0.025083</td>\n",
              "      <td>0.099108</td>\n",
              "      <td>0.077162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.224392</td>\n",
              "      <td>0.118985</td>\n",
              "      <td>0.329432</td>\n",
              "      <td>0.372088</td>\n",
              "      <td>0.361005</td>\n",
              "      <td>0.015501</td>\n",
              "      <td>-0.194347</td>\n",
              "      <td>-0.098181</td>\n",
              "      <td>0.270375</td>\n",
              "      <td>0.267279</td>\n",
              "      <td>-0.162258</td>\n",
              "      <td>-0.317084</td>\n",
              "      <td>-0.011567</td>\n",
              "      <td>0.100413</td>\n",
              "      <td>-0.050224</td>\n",
              "      <td>-0.136009</td>\n",
              "      <td>-0.177037</td>\n",
              "      <td>-0.130498</td>\n",
              "      <td>-0.054766</td>\n",
              "      <td>-0.018691</td>\n",
              "      <td>0.023954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.087817</td>\n",
              "      <td>-0.068345</td>\n",
              "      <td>0.306967</td>\n",
              "      <td>0.330923</td>\n",
              "      <td>0.249144</td>\n",
              "      <td>0.006884</td>\n",
              "      <td>-0.265423</td>\n",
              "      <td>-0.172700</td>\n",
              "      <td>0.266434</td>\n",
              "      <td>0.332695</td>\n",
              "      <td>-0.100749</td>\n",
              "      <td>-0.298524</td>\n",
              "      <td>0.037439</td>\n",
              "      <td>0.219153</td>\n",
              "      <td>0.062837</td>\n",
              "      <td>-0.048885</td>\n",
              "      <td>-0.053074</td>\n",
              "      <td>-0.088550</td>\n",
              "      <td>-0.031346</td>\n",
              "      <td>0.108610</td>\n",
              "      <td>0.079244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  ...  MFCCs_20  MFCCs_21  MFCCs_22\n",
              "0       1.0  0.152936 -0.105586  ...  0.057684  0.118680  0.014038\n",
              "1       1.0  0.171534 -0.098975  ...  0.020140  0.082263  0.029056\n",
              "2       1.0  0.152317 -0.082973  ... -0.025083  0.099108  0.077162\n",
              "3       1.0  0.224392  0.118985  ... -0.054766 -0.018691  0.023954\n",
              "4       1.0  0.087817 -0.068345  ... -0.031346  0.108610  0.079244\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GFuHSkRGrN4",
        "outputId": "d38c9ea1-0601-42cf-a6ca-076cdc64a997"
      },
      "source": [
        "# Labels:\n",
        "labels=datos.iloc[:,24]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       AdenomeraAndre\n",
              "1       AdenomeraAndre\n",
              "2       AdenomeraAndre\n",
              "3       AdenomeraAndre\n",
              "4       AdenomeraAndre\n",
              "             ...      \n",
              "7190       ScinaxRuber\n",
              "7191       ScinaxRuber\n",
              "7192       ScinaxRuber\n",
              "7193       ScinaxRuber\n",
              "7194       ScinaxRuber\n",
              "Name: Species, Length: 7195, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7uzSyetHeC7",
        "outputId": "c89bf584-14fe-41fa-8582-8934fa061ab7"
      },
      "source": [
        "# Se extraen las distintas clases:\n",
        "names=labels.unique().tolist()\n",
        "print(names)\n",
        "len(names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AdenomeraAndre', 'Ameeregatrivittata', 'AdenomeraHylaedactylus', 'HylaMinuta', 'HypsiboasCinerascens', 'HypsiboasCordobae', 'LeptodactylusFuscus', 'OsteocephalusOophagus', 'Rhinellagranulosa', 'ScinaxRuber']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJrHMOWCIVSi",
        "outputId": "42b50415-1a5e-4825-db8c-54f97b6f1a8c"
      },
      "source": [
        "# Transformación de Labels:\n",
        "Class=0\n",
        "for i in names:\n",
        "  labels=labels.replace(i,Class)\n",
        "  Class=Class+1\n",
        "print(labels.unique().tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9CdKQArpikt"
      },
      "source": [
        "**Parte 2:** Modifique la función bench_k_means( ) agregando una columna extra, correspondiente al número de clusters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe7DxQjDN3oF"
      },
      "source": [
        "# Función predefinida\n",
        "def bench_k_means(kmeans, name, data, labels):\n",
        "\n",
        "    t0 = time()\n",
        "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
        "    fit_time = time() - t0\n",
        "    results = [name, fit_time, estimator[-1].inertia_]\n",
        "\n",
        "    # Define the metrics which require only the true labels and estimator\n",
        "    # labels\n",
        "    clustering_metrics = [\n",
        "        metrics.homogeneity_score,\n",
        "        metrics.completeness_score,\n",
        "        metrics.v_measure_score,\n",
        "        metrics.adjusted_rand_score,\n",
        "        metrics.adjusted_mutual_info_score,\n",
        "    ]\n",
        "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
        "\n",
        "    # The silhouette score requires the full dataset\n",
        "    results += [\n",
        "        metrics.silhouette_score(data, estimator[-1].labels_,\n",
        "                                 metric=\"euclidean\", sample_size=300,)\n",
        "    ]\n",
        "\n",
        "    # Número de Clusters:\n",
        "    x=pd.DataFrame(estimator[-1].labels_)\n",
        "    x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "    cluster_group=x['cluster'].unique().tolist() \n",
        "    num=len(cluster_group)\n",
        "    results+=[num]\n",
        "\n",
        "    # Show the results\n",
        "    formatter_result = (\"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\"\n",
        "                        \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.0f}\")\n",
        "    print(formatter_result.format(*results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By1e29HhN4Iw",
        "outputId": "9387df1a-879a-45a4-a5e2-2ae7f5c315e4"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10, n_init=4,\n",
        "                random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=6, n_init=4, random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
        "\n",
        "pca = PCA(n_components=9).fit(data)\n",
        "kmeans = KMeans(init=pca.components_, n_clusters=9, n_init=1)\n",
        "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "k-means++\t0.274s\t51996\t0.708\t0.571\t0.633\t0.432\t0.631\t0.254\t10\n",
            "random   \t0.115s\t67625\t0.588\t0.614\t0.600\t0.499\t0.600\t0.255\t6\n",
            "PCA-based\t0.109s\t62881\t0.719\t0.718\t0.719\t0.871\t0.718\t0.361\t9\n",
            "__________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thu3UtrlpitK"
      },
      "source": [
        "**Parte 3:** Implemente una nueva función bench_clustering2( ), tomando como base la función\n",
        "bench_k_means( ) modificada en el punto anterior. Esta función será usada para obtener un\n",
        "benchmark tanto de DBSCAN como del clustering aglomerativo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRd_THfJnbsw"
      },
      "source": [
        "def bench_clustering2(clustering, name, data, labels,opcion=True): \n",
        "    t0 = time()\n",
        "    estimator = make_pipeline(StandardScaler(), clustering).fit(data)\n",
        "    fit_time = time() - t0\n",
        "    data1=data # Se redefine data para evitar algún eventual error al ser modificada\n",
        "    labels1=labels # Se redefine labels para evitar algún eventual error al ser modificada\n",
        "\n",
        "    if name=='k-means random' or name=='k-means++' : # Solo si el nombre es kmeans se calculará la metrica inertia_\n",
        "      results = [name, fit_time, int(round(estimator[-1].inertia_,0))]\n",
        "    else:\n",
        "      results = [name, fit_time,None] # En otro caso, se obtiene None\n",
        "    \n",
        "    if opcion==True: # True no considera outlier como grupo\n",
        "      u=pd.DataFrame(estimator[-1].labels_) # DataFrame de las clasificaciones para eliminar las filas correspondientes con la función drop\n",
        "      x=estimator[-1].labels_.tolist() # lista de los clusters para la extracción de indices \n",
        "      indices=[ i  for i in range(len(x)) if x[i]==-1 ] # Extracción de indices en donde el cluster fue -1\n",
        "  \n",
        "      for i in indices: # Se itera sobre los indices donde se encontraron -1 para eliminar las filas asociadas a ese cluster\n",
        "        data1=data1.drop(i,axis=0) # Se eliminan filas asociadas a los clusters -1\n",
        "        labels1=labels1.drop(i,axis=0) # Se eliminan labels asociados a los clusters -1\n",
        "        u=u.drop(i,axis=0) # Se eliminan -1 de los clusters\n",
        "      u=u.to_numpy().flatten() # Correción de un problema de dimensionalidad\n",
        "\n",
        "      # Metricas:\n",
        "      clustering_metrics = [\n",
        "        metrics.homogeneity_score,\n",
        "        metrics.completeness_score,\n",
        "        metrics.v_measure_score,\n",
        "        metrics.adjusted_rand_score,\n",
        "        metrics.adjusted_mutual_info_score,]\n",
        "      results += [m(labels1, u)  for m in clustering_metrics] # Metricas reciben como input los labels y clusters actualizados sin los clusters asociados a -1\n",
        "      \n",
        "      try: # Se intenta calcular la metrica silhouette\n",
        "        results += [\n",
        "        round(metrics.silhouette_score(data1, u,\n",
        "                                  metric=\"euclidean\"),3)] # Metricas reciben como input los labels y clusters actualizados sin los clusters asociados a -1\n",
        "      except: \n",
        "        results +=[None] # En el caso que no pueda ser calculada se obtiene None\n",
        "\n",
        "      # Se contabilizan los Clusters:\n",
        "      x=pd.DataFrame(estimator[-1].labels_)\n",
        "      x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "      cluster_group=x['cluster'].unique().tolist()\n",
        "      if -1 in cluster_group: # Si hay cluster -1 este se elimina\n",
        "        cluster_group.remove(-1)\n",
        "      num=len(cluster_group)\n",
        "      results+=[num]\n",
        "      \n",
        "     \n",
        "    if opcion==False:  # False considera outlier como grupo\n",
        "      \n",
        "      # Metricas:\n",
        "      clustering_metrics = [\n",
        "        metrics.homogeneity_score,\n",
        "        metrics.completeness_score,\n",
        "        metrics.v_measure_score,\n",
        "        metrics.adjusted_rand_score,\n",
        "        metrics.adjusted_mutual_info_score,]\n",
        "      results += [m(labels, estimator[-1].labels_)  for m in clustering_metrics]\n",
        "\n",
        "      try: # Se intenta calcular la metrica silhouette\n",
        "        results += [\n",
        "          round(metrics.silhouette_score(data, estimator[-1].labels_,\n",
        "                                  metric=\"euclidean\"),3)]\n",
        "      except:\n",
        "        results +=[None] # En el caso que no pueda ser calculada se obtiene None\n",
        "\n",
        "      # Se contabilizan los Clusters:\n",
        "      x=pd.DataFrame(estimator[-1].labels_)\n",
        "      x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "      cluster_group=x['cluster'].unique().tolist() # Se consideran clusters -1\n",
        "      num=len(cluster_group)\n",
        "      results+=[num]\n",
        "\n",
        "    # Show the results\n",
        "    formatter_result = (\"{:9s}\\t{:.3f}s\\t{:}\\t{:.3f}\\t{:.3f}\"\n",
        "                        \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:}\\t{:.0f}\")\n",
        "    print(formatter_result.format(*results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoOFAwmJpi1h"
      },
      "source": [
        "**Parte 4:** Hacer pruebas con distintas variantes de algoritmos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp37CsHlzpak"
      },
      "source": [
        "**a)** K-Means (con inicialización al azar):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ84oeQgFnPD",
        "outputId": "909a8b47-2e04-41ab-c429-a55491ad0e9c"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=10, n_init=4, random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means random\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "k-means random\t0.311s\t54400\t0.641\t0.507\t0.566\t0.326\t0.565\t0.224\t10\n",
            "__________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GluW3iTzv_w"
      },
      "source": [
        "**b)** K-means++:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3r44FLcFnxY",
        "outputId": "1551c5ee-821f-4791-a4a7-b74fcce9a655"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10, n_init=4,\n",
        "                random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "k-means++\t0.297s\t51996\t0.708\t0.571\t0.633\t0.432\t0.631\t0.236\t10\n",
            "__________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VpG9H46zwlq"
      },
      "source": [
        "**c)** DBSCAN con épsilon por defecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7K6FLUwFoNF",
        "outputId": "a25af164-9df9-49ce-f2c2-911b4748254b"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN()\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels)\n",
        "print(90 * '_')\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.565s\tNone\t1.000\t0.327\t0.493\t0.256\t0.483\t0.246\t8\n",
            "__________________________________________________________________________________________\n",
            "[-1, 0, 1, 2, 3, 4, 5, 6, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O_bIlSlzwuO"
      },
      "source": [
        "**d)** DBSCAN con épsilon 0.7:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5lndnStFotg",
        "outputId": "47ee6797-5a69-47c6-863b-777156f71fd3"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels)\n",
        "print(90 * '_')\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.744s\tNone\t1.000\t0.585\t0.738\t0.450\t0.730\t0.546\t13\n",
            "__________________________________________________________________________________________\n",
            "[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l282Q_ZXzw2-"
      },
      "source": [
        "**e)** DBSCAN con épsilon 0.2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu_YuEJ5Fpn_",
        "outputId": "1b96033d-0e15-4422-99bd-0f546834842a"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels)\n",
        "print(90 * '_')\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.395s\tNone\t1.000\t0.000\t0.000\t0.000\t0.000\t0.52\t2\n",
            "__________________________________________________________________________________________\n",
            "[-1, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPA95G6ozw_x"
      },
      "source": [
        "**f)** DBSCAN con épsilon por defecto, agregando outliers a cluster extra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnOahZ3BFqLm",
        "outputId": "9cd6eef1-c16f-4597-cddc-3c12a3de5e28"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN( )\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels,opcion=False)\n",
        "print(90 * '_')\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.604s\tNone\t0.074\t0.451\t0.127\t0.049\t0.123\t-0.21\t9\n",
            "__________________________________________________________________________________________\n",
            "[-1, 0, 1, 2, 3, 4, 5, 6, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfsfi75gzxJZ"
      },
      "source": [
        "**g)** DBSCAN con épsilon 0.7, agregando outliers a cluster extra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k36DDZwpFqmn",
        "outputId": "fbbe3735-e717-436c-f7e4-a6c2d5f3ba77"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels,opcion=False)\n",
        "print(90 * '_')\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.710s\tNone\t0.179\t0.545\t0.270\t0.133\t0.265\t-0.343\t14\n",
            "__________________________________________________________________________________________\n",
            "[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK5Cs28OzxUR"
      },
      "source": [
        "**h)** DBSCAN con épsilon 0.2, agregando outliers a cluster extra:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXyXNXnDFrGU",
        "outputId": "84348492-acd4-4da3-b082-066ba34f250e"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels,opcion=False)\n",
        "print(90 * '_')\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.345s\tNone\t0.011\t0.677\t0.022\t0.006\t0.021\t-0.094\t3\n",
            "__________________________________________________________________________________________\n",
            "[-1, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGFTaarIzxjh"
      },
      "source": [
        "**i)** Clustering aglomerativo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ZrXG6EFrux",
        "outputId": "611f172e-7cf9-44e8-9087-b8812760b28d"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = AgglomerativeClustering(n_clusters=10)\n",
        "bench_clustering2(clustering=clustering, name=\"Agglomerative\", data=data, labels=labels)\n",
        "print(90 * '_')\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "Agglomerative\t1.824s\tNone\t0.789\t0.661\t0.719\t0.590\t0.718\t0.239\t10\n",
            "__________________________________________________________________________________________\n",
            "[4, 0, 1, 3, 8, 9, 6, 2, 5, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADEcVGzuzxqy"
      },
      "source": [
        "**j)** Repetir todas las pruebas anteriores, después de usar PCA sobre los datos para reducirlos a\n",
        "2 dimensiones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CH2RtaQFsEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a38857-150c-4708-f430-ce87db7cd605"
      },
      "source": [
        "# PCA a data:\n",
        "pca=PCA(n_components=2)\n",
        "pca.fit(data)\n",
        "data=pd.DataFrame(pca.transform(data))\n",
        "print(data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1\n",
            "0 -0.469179 -0.695615\n",
            "1 -0.514870 -0.721527\n",
            "2 -0.476569 -0.704513\n",
            "3 -0.537135 -0.590022\n",
            "4 -0.501557 -0.768868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kaZTj0Ikmb5"
      },
      "source": [
        "**a)** K-Means (con inicialización al azar):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V7eiD9Mkmb-",
        "outputId": "c7cf5cc3-72f2-477d-b089-91897033a22b"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=10, n_init=4, random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means random\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "k-means random\t0.206s\t1044\t0.616\t0.479\t0.539\t0.318\t0.537\t0.398\t10\n",
            "__________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0TEM9NJkmb_"
      },
      "source": [
        "**b)** K-means++:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ephlIFrzkmcA",
        "outputId": "e195fa41-c392-4019-bb4f-709a5323ebb2"
      },
      "source": [
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10, n_init=4,\n",
        "                random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "k-means++\t0.162s\t943\t0.654\t0.497\t0.565\t0.355\t0.564\t0.413\t10\n",
            "__________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hctu_6qskmcA"
      },
      "source": [
        "**c)** DBSCAN con épsilon por defecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxDka5eYkmcA",
        "outputId": "fcf54d18-1c2d-40ab-aa6c-7b5f457b9549"
      },
      "source": [
        "print(90 * '_')\n",
        "\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN()\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.210s\tNone\t0.000\t1.000\t0.000\t0.000\t0.000\tNone\t1\n",
            "__________________________________________________________________________________________\n",
            "[0, -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kO7wsXdkmcB"
      },
      "source": [
        "**d)** DBSCAN con épsilon 0.7:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7g2JN07kmcB",
        "outputId": "301e2812-baf1-4eed-cce4-727b94acca31"
      },
      "source": [
        "print(90 * '_')\n",
        "\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.271s\tNone\t-0.000\t1.000\t-0.000\t0.000\t-0.000\tNone\t1\n",
            "__________________________________________________________________________________________\n",
            "[0, -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IL9cprlkmcC"
      },
      "source": [
        "**e)** DBSCAN con épsilon 0.2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgtS-rB-kmcC",
        "outputId": "a0355b27-c647-4bf1-923c-9326de2b9a3f"
      },
      "source": [
        "print(90 * '_')\n",
        "\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.204s\tNone\t0.002\t0.198\t0.004\t-0.001\t0.003\t0.031\t3\n",
            "__________________________________________________________________________________________\n",
            "[0, -1, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeqTWFyokmcC"
      },
      "source": [
        "**f)** DBSCAN con épsilon por defecto, agregando outliers a cluster extra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH9KJ2FTkmcD",
        "outputId": "7e27fe9e-19e2-4ba8-b35c-40e99058af55"
      },
      "source": [
        "print(90 * '_')\n",
        "\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN( )\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.212s\tNone\t0.000\t0.120\t0.001\t-0.000\t0.000\t0.484\t2\n",
            "__________________________________________________________________________________________\n",
            "[0, -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKnLKFmjkmcD"
      },
      "source": [
        "**g)** DBSCAN con épsilon 0.7, agregando outliers a cluster extra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Db-jG58kmcD",
        "outputId": "886b24dd-99bd-4308-c82a-7d2ca5a76afc"
      },
      "source": [
        "print(90 * '_')\n",
        "\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.268s\tNone\t0.000\t0.074\t0.000\t-0.000\t-0.000\t0.519\t2\n",
            "__________________________________________________________________________________________\n",
            "[0, -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq7IethmkmcE"
      },
      "source": [
        "**h)** DBSCAN con épsilon 0.2, agregando outliers a cluster extra:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePq0CgDXkmcE",
        "outputId": "548b75ec-1c77-4f8f-cd25-7a1a48f1e892"
      },
      "source": [
        "print(90 * '_')\n",
        "\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "DBSCAN   \t0.123s\tNone\t0.004\t0.103\t0.007\t0.001\t0.005\t0.019\t4\n",
            "__________________________________________________________________________________________\n",
            "[0, -1, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYIj4pBNkmcE"
      },
      "source": [
        "**i)** Clustering aglomerativo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndRYAGwskmcE",
        "outputId": "76a32383-5feb-49eb-d609-52e311d695a2"
      },
      "source": [
        "print(90 * '_')\n",
        "\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "clustering = AgglomerativeClustering(n_clusters=10)\n",
        "bench_clustering2(clustering=clustering, name=\"Agglomerative\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "x=pd.DataFrame(clustering.labels_)\n",
        "x.set_axis(['cluster'], axis=1, inplace=True)\n",
        "cluster_group=x['cluster'].unique().tolist()\n",
        "print(cluster_group)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "Agglomerative\t1.333s\tNone\t0.649\t0.490\t0.558\t0.350\t0.557\t0.377\t10\n",
            "__________________________________________________________________________________________\n",
            "[0, 4, 5, 3, 8, 2, 1, 9, 7, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs9SXghIpi8I"
      },
      "source": [
        "**Parte 5:** Analice los resultados obtenidos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inCybG9frxLT"
      },
      "source": [
        "**a)** Compare los algoritmos aplicados en base a cuatro métricas (completeness, homogeneity, vmeasure,\n",
        "silhouette), indicando: (i) cuál variante es mejor según cada métrica y (ii) cuál\n",
        "variante es peor según cada métrica. Se debe considerar tanto los datos originales como los\n",
        "casos en los cuales se aplicó PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-JxSNszWleA"
      },
      "source": [
        "**A continuación se deja un cuadro resumen con los resultados para tener una mejor visualización.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JDCznkXWdDk",
        "outputId": "2efd8338-ce6e-4f00-b347-51ac07675f76"
      },
      "source": [
        "print('Sin PCA')\n",
        "print(90 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsil\\t# Clusters')\n",
        "\n",
        "data=features\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=10, n_init=4, random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means random\", data=data, labels=labels)\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10, n_init=4,random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN()\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN def\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.7\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.2\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN( )\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN def-1\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.7-1\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.2-1\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "clustering = AgglomerativeClustering(n_clusters=10)\n",
        "bench_clustering2(clustering=clustering, name=\"Agglomerative\", data=data, labels=labels)\n",
        "print(90 * '_')\n",
        "\n",
        "print('PCA')\n",
        "\n",
        "print(90 * '_')\n",
        "\n",
        "# PCA a data:\n",
        "pca=PCA(n_components=2)\n",
        "pca.fit(data)\n",
        "data=pd.DataFrame(pca.transform(data))\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=10, n_init=4, random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means random\", data=data, labels=labels)\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10, n_init=4,random_state=0)\n",
        "bench_clustering2(clustering=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN()\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN def\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.7\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.2\", data=data, labels=labels)\n",
        "\n",
        "clustering = DBSCAN( )\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN def-1\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "clustering = DBSCAN(eps=0.7)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.7-1\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "clustering = DBSCAN(eps=0.2)\n",
        "bench_clustering2(clustering=clustering, name=\"DBSCAN 0.2-1\", data=data, labels=labels,opcion=False)\n",
        "\n",
        "clustering = AgglomerativeClustering(n_clusters=10)\n",
        "bench_clustering2(clustering=clustering, name=\"Agglomerative\", data=data, labels=labels)\n",
        "\n",
        "print(90 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sin PCA\n",
            "__________________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsil\t# Clusters\n",
            "k-means random\t0.297s\t54400\t0.641\t0.507\t0.566\t0.326\t0.565\t0.224\t10\n",
            "k-means++\t0.257s\t51996\t0.708\t0.571\t0.633\t0.432\t0.631\t0.236\t10\n",
            "DBSCAN def\t0.556s\tNone\t1.000\t0.327\t0.493\t0.256\t0.483\t0.246\t8\n",
            "DBSCAN 0.7\t0.744s\tNone\t1.000\t0.585\t0.738\t0.450\t0.730\t0.546\t13\n",
            "DBSCAN 0.2\t0.385s\tNone\t1.000\t0.000\t0.000\t0.000\t0.000\t0.52\t2\n",
            "DBSCAN def-1\t0.600s\tNone\t0.074\t0.451\t0.127\t0.049\t0.123\t-0.21\t9\n",
            "DBSCAN 0.7-1\t0.690s\tNone\t0.179\t0.545\t0.270\t0.133\t0.265\t-0.343\t14\n",
            "DBSCAN 0.2-1\t0.338s\tNone\t0.011\t0.677\t0.022\t0.006\t0.021\t-0.094\t3\n",
            "Agglomerative\t1.829s\tNone\t0.789\t0.661\t0.719\t0.590\t0.718\t0.239\t10\n",
            "__________________________________________________________________________________________\n",
            "PCA\n",
            "__________________________________________________________________________________________\n",
            "k-means random\t0.243s\t1044\t0.616\t0.479\t0.539\t0.318\t0.537\t0.398\t10\n",
            "k-means++\t0.165s\t943\t0.654\t0.497\t0.565\t0.355\t0.564\t0.413\t10\n",
            "DBSCAN def\t0.199s\tNone\t0.000\t1.000\t0.000\t0.000\t0.000\tNone\t1\n",
            "DBSCAN 0.7\t0.263s\tNone\t-0.000\t1.000\t-0.000\t0.000\t-0.000\tNone\t1\n",
            "DBSCAN 0.2\t0.111s\tNone\t0.002\t0.198\t0.004\t-0.001\t0.003\t0.031\t3\n",
            "DBSCAN def-1\t0.204s\tNone\t0.000\t0.120\t0.001\t-0.000\t0.000\t0.484\t2\n",
            "DBSCAN 0.7-1\t0.255s\tNone\t0.000\t0.074\t0.000\t-0.000\t-0.000\t0.519\t2\n",
            "DBSCAN 0.2-1\t0.111s\tNone\t0.004\t0.103\t0.007\t0.001\t0.005\t0.019\t4\n",
            "Agglomerative\t1.340s\tNone\t0.649\t0.490\t0.558\t0.350\t0.557\t0.377\t10\n",
            "__________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xcZIZNinWfJ"
      },
      "source": [
        "**Según la métrica completeness**: El mejor es DBSCAN 0.2-1 sin PCA (los que tienen valor 1.0 no son considerados al tener solo 1 cluster) y el peor es DBSCAN 0.2 sin PCA. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUB7zAnYHhbA"
      },
      "source": [
        "\n",
        "**Según la métrica  homogeneity**: Los mejores son DBSCAN def sin PCA, DBSCAN 0.7 sin PCA y DBSCAN 0.2 sin PCA y los peores fueron DBSCAN def con PCA, DBSCAN 0.7 con PCA, DBSCAN def-1 con PCA y DBSCAN 0.7-1 con PCA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPjz2gU0Hlol"
      },
      "source": [
        "\n",
        "**Según la métrica  vmeasure**: El mejor es DBSCAN 0.7 sin PCA y los peores fueron DBSCAN def con PCA, DBSCAN 0.7 con PCA, DBSCAN def 0.7-1 con PCA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evI75HH4Ho4M"
      },
      "source": [
        "\n",
        "\n",
        "**Según la métrica silhouette**: El mejor fue DBSCAN 0.7 sin PCA y el peor fue DBSCAN 0.2-1 con PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQiHgMjrzDJv"
      },
      "source": [
        "**b)** Indique en cuáles casos no fue posible calcular las métricas de DBSCAN. Analice el número\n",
        "de clusters obtenidos por DBSCAN y su efecto sobre las métricas. Analice el efecto de\n",
        "considerar o no los outliers de DBSCAN como un cluster extra y su efecto sobre las\n",
        "métricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR1ZhPu9Y5O0"
      },
      "source": [
        "**Cuando DBSCAN entregaba solo 1 cluster no era posible calcular \"Silhouette\" y en las demás métricas se obtienen valores nulos. DBSCAN al aumentar sus clusters se observa una tendencia a aumentar el valor de las métricas.**\n",
        "\n",
        "**El efecto que tiene considerar los outliers como un cluster adicional es que si es posible calcular \"Silhouette\", ya que hay por lo menos 2 clusters, el asociado a -1 y el otro que arma de por si el algoritmo. Finalmente al considerar los outliers como cluster el desempeño de las métricas disminuye, lo cual tiene sentido, ya que los outliers son un grupo disperso por todo el espacio.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LKUzy9PzGWG"
      },
      "source": [
        "**c)** Analice el efecto de usar PCA sobre las métricas obtenidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLQRjWNPY53b"
      },
      "source": [
        "**El primer punto a destacar es que PCA reduce los tiempos de entrenamiento debido al menor volumen de procesamiento de datos. En cuanto a las métricas, PCA tiende a disminuir la calidad de las metricas de la agrupaciones, esto se asocia a que las variables contienen información que se pierde, de modo que la calidad de agrupamiento disminuye. Sin embargo, cabe destacar que hay algunas excepciones en donde las metricas mejoran (ver caso k-means)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXXJfvfR-uLh"
      },
      "source": [
        "# **Conclusiones:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xYcGSuM0cxW"
      },
      "source": [
        "**En esta tarea se aprendio a programar algoritmos de clustering y a evaluar los desempeños según distintas métricas. También se comprendio el efecto del PCA en la calidad de los clustering y su tiempo de entrenamiento.**\n",
        "\n",
        "**En cuanto a objetivos y resultados, se puede decir que se cumplio a cabalidad con todos los requerimientos de la tarea y los resultados obtenidos concuerdan con la teoría, ya que PCA disminuye tiempos de entrenamiento, pero reduce desempeño y en general el mejor algoritmo fue DBSCAN, el cual a su vez tuvo mayor tiempo de entrenamiento al ser un algoritmo de densidad.**\n",
        "\n",
        "**En cuanto a dificultades, la mayor dificultad fue entender el código base para agregarle nuevo código para implementar otras funcionalidades.**\n",
        "\n",
        "**Finalmente la mejor solución fue DBSCAN 0.7 sin PCA.**\n",
        "\n",
        "**Para mejorar el desempeño de los algoritmos, se recomienda hacer un estudio más detallado de los hiperparámetros, como lo es la cantidad de veces que se resuelve k-means para obtener el agrupamiento con mejor desempeño, de modo de encontrar un equilibrio mayor entre tiempo de entrenamiento y desempeño, priorizando en este caso desempeño ya que los tiempos son bajos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pzu_93VvCDF",
        "outputId": "035f33e4-5564-4600-8286-b7e93b7b8bfb"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWceb3-kvDde"
      },
      "source": [
        "#%cd /content/drive/MyDrive/Colab Notebooks "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aYsX4sDvK6Y"
      },
      "source": [
        "#Install:\n",
        "#!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-generic-recommended"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUjQuds9vc14"
      },
      "source": [
        "#A PDF:\n",
        "#!jupyter nbconvert --to pdf tarea5ic.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}